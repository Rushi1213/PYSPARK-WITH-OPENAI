{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BlUmnIST0ew8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (0.0.352)\n",
            "Requirement already satisfied: openai in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (0.27.8)\n",
            "Requirement already satisfied: pyspark-ai in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (0.1.19)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/316.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:04:13\u001b[0m^C\n",
            "\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/316.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:04:14\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pip install langchain openai pyspark-ai pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark-ai[ingestion]\n",
            "  Obtaining dependency information for pyspark-ai[ingestion] from https://files.pythonhosted.org/packages/98/5f/f09f9090aebe64e3e8da73dcfb0d04f8805059d0f6155597574d335fcd57/pyspark_ai-0.1.19-py3-none-any.whl.metadata\n",
            "  Using cached pyspark_ai-0.1.19-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain<0.1.0,>=0.0.271 (from pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for langchain<0.1.0,>=0.0.271 from https://files.pythonhosted.org/packages/0f/36/58f4d9df45436670a5b6b82ff48522b6233fa35bd21b133b149c1c7ec8bd/langchain-0.0.352-py3-none-any.whl.metadata\n",
            "  Using cached langchain-0.0.352-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: openai<0.28.0,>=0.27.8 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyspark-ai[ingestion]) (0.27.8)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.10.10 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyspark-ai[ingestion]) (1.10.10)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.15.1 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyspark-ai[ingestion]) (2.15.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyspark-ai[ingestion]) (4.12.2)\n",
            "Collecting google-api-python-client<3.0.0,>=2.90.0 (from pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for google-api-python-client<3.0.0,>=2.90.0 from https://files.pythonhosted.org/packages/62/1b/3ff6bd5f33c1a1780835725014ac480128d2d1e3244b2809275d0fa4f726/google_api_python_client-2.111.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading google_api_python_client-2.111.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyspark-ai[ingestion]) (2.31.0)\n",
            "Requirement already satisfied: tiktoken==0.4.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyspark-ai[ingestion]) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from tiktoken==0.4.0->pyspark-ai[ingestion]) (2023.8.8)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->pyspark-ai[ingestion]) (2.4.1)\n",
            "Collecting httplib2<1.dev0,>=0.15.0 (from google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Collecting google-auth<3.0.0.dev0,>=1.19.0 (from google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for google-auth<3.0.0.dev0,>=1.19.0 from https://files.pythonhosted.org/packages/f4/d2/9f6f3b9c0fd486617816cff42e856afea079d0bad99f0e60dc186c76b881/google_auth-2.25.2-py2.py3-none-any.whl.metadata\n",
            "  Downloading google_auth-2.25.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting google-auth-httplib2>=0.1.0 (from google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for google-auth-httplib2>=0.1.0 from https://files.pythonhosted.org/packages/be/8a/fe34d2f3f9470a27b01c9e76226965863f153d5fbe276f83608562e49c04/google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 from https://files.pythonhosted.org/packages/d6/c9/0462f037b62796fbda4801be62d0ae3147eaeb99e2939661580c98abe3eb/google_api_core-2.15.0-py3-none-any.whl.metadata\n",
            "  Downloading google_api_core-2.15.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (2.0.17)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (0.5.9)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for langchain-community<0.1,>=0.0.2 from https://files.pythonhosted.org/packages/bc/69/b97f59cfe0ea85736e0ad0f5c41f37ab713ed1e576e468d72267a1da3d40/langchain_community-0.0.6-py3-none-any.whl.metadata\n",
            "  Downloading langchain_community-0.0.6-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting langchain-core<0.2,>=0.1 (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for langchain-core<0.2,>=0.1 from https://files.pythonhosted.org/packages/42/1e/61e05c0997de81e767a90668f9039771a76dbd474b3d337469501889bc06/langchain_core-0.1.3-py3-none-any.whl.metadata\n",
            "  Downloading langchain_core-0.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.70 (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for langsmith<0.1.0,>=0.0.70 from https://files.pythonhosted.org/packages/c0/a2/7814b2341d2919f8305cdaff2e37f76b04c45839f402a38cf13ef7153bea/langsmith-0.0.75-py3-none-any.whl.metadata\n",
            "  Downloading langsmith-0.0.75-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (1.25.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from openai<0.28.0,>=0.27.8->pyspark-ai[ingestion]) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from pydantic<2.0.0,>=1.10.10->pyspark-ai[ingestion]) (4.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->pyspark-ai[ingestion]) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->pyspark-ai[ingestion]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->pyspark-ai[ingestion]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->pyspark-ai[ingestion]) (2023.5.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (0.9.0)\n",
            "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for googleapis-common-protos<2.0.dev0,>=1.56.2 from https://files.pythonhosted.org/packages/f0/43/c9d8f75ddf08e2a0a27db243c13a700c3cc7ec615b545b697cf6f715ad92/googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion]) (4.23.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion]) (5.3.1)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.15.0->google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
            "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
            "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (2.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (1.1.2)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client<3.0.0,>=2.90.0->pyspark-ai[ingestion])\n",
            "  Obtaining dependency information for pyasn1<0.6.0,>=0.4.6 from https://files.pythonhosted.org/packages/d1/75/4686d2872bf2fc0b37917cbc8bbf0dd3a5cdb0990799be1b9cbf1e1eb733/pyasn1-0.5.1-py2.py3-none-any.whl.metadata\n",
            "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/anaconda3/envs/langchain/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.1.0,>=0.0.271->pyspark-ai[ingestion]) (1.0.0)\n",
            "Downloading google_api_python_client-2.111.0-py2.py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.0.352-py3-none-any.whl (794 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyspark_ai-0.1.19-py3-none-any.whl (35 kB)\n",
            "Using cached google_api_core-2.15.0-py3-none-any.whl (121 kB)\n",
            "Downloading google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_community-0.0.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.3-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.0.75-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
            "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
            "Installing collected packages: uritemplate, pyparsing, pyasn1, packaging, jsonpointer, googleapis-common-protos, rsa, pyasn1-modules, langsmith, jsonpatch, httplib2, langchain-core, google-auth, google-auth-httplib2, google-api-core, langchain-community, google-api-python-client, langchain, pyspark-ai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.0.22\n",
            "    Uninstalling langsmith-0.0.22:\n",
            "      Successfully uninstalled langsmith-0.0.22\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.0.150\n",
            "    Uninstalling langchain-0.0.150:\n",
            "      Successfully uninstalled langchain-0.0.150\n",
            "Successfully installed google-api-core-2.15.0 google-api-python-client-2.111.0 google-auth-2.25.2 google-auth-httplib2-0.2.0 googleapis-common-protos-1.62.0 httplib2-0.22.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.352 langchain-community-0.0.6 langchain-core-0.1.3 langsmith-0.0.75 packaging-23.2 pyasn1-0.5.1 pyasn1-modules-0.3.0 pyparsing-3.1.1 pyspark-ai-0.1.19 rsa-4.9 uritemplate-4.1.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark-ai[ingestion]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atPI6Zru15eF"
      },
      "source": [
        "1. set an openai key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H2DRMB1w0ihI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "# os.environ['OPENAI_API_KEY'] = 'YOUR_OPENAI_KEY'\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYYFWSbc1x-_"
      },
      "source": [
        "\n",
        "2. Initialize the Spark AI instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "evnU0Wha00pP"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from pyspark_ai import SparkAI\n",
        "\n",
        "# If 'gpt-4' is unavailable, use 'gpt-3.5-turbo' (might lower output quality)\n",
        "llm = ChatOpenAI(model_name='gpt-4', temperature=0)\n",
        "\n",
        "spark_ai = SparkAI(llm=llm, verbose=True)\n",
        "\n",
        "# Activate partial functions for Spark DataFrame\n",
        "spark_ai.activate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdX946LQ2y6G"
      },
      "source": [
        "3. Create a dataframe via a HTTP URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3-82Xpo058i",
        "outputId": "65314764-5dea-45e5-ee13-5ec73a03a092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO: \u001b[0mParsing URL: https://finance.yahoo.com/quote/AAPL/holders?p=AAPL\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:spark_ai:Parsing URL: https://finance.yahoo.com/quote/AAPL/holders?p=AAPL\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO: \u001b[0mSQL query for the ingestion:\n",
            "\u001b[34mCREATE\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mOR\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mREPLACE\u001b[39;49;00m\u001b[37m \u001b[39;49;00mTEMP\u001b[37m \u001b[39;49;00m\u001b[34mVIEW\u001b[39;49;00m\u001b[37m \u001b[39;49;00mspark_ai_temp_view_630261\u001b[37m \u001b[39;49;00m\u001b[34mAS\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mSELECT\u001b[39;49;00m\u001b[37m \u001b[39;49;00m*\u001b[37m \u001b[39;49;00m\u001b[34mFROM\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mVALUES\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Vanguard Group Inc'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1299997133\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m8\u001b[39;49;00m.\u001b[34m36\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m251653447386\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Blackrock Inc.'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1031407553\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m6\u001b[39;49;00m.\u001b[34m63\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m199659875998\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Berkshire Hathaway, Inc'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m915560382\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m5\u001b[39;49;00m.\u001b[34m89\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m177234180424\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'State Street Corporation'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m569291690\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m3\u001b[39;49;00m.\u001b[34m66\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m110203486392\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'FMR, LLC'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m298321726\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m92\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m57749120265\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Geode Capital Management, LLC'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m296103070\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m90\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m57319632832\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Price (T.Rowe) Associates Inc'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m216307878\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m39\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m41872879419\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Morgan Stanley'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m206732960\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m33\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m40019366775\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Northern Trust Corporation'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m168874976\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m09\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m32690818163\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Norges Bank Investment Management'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m167374278\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Dec 30, 2022'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m08\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m32400313041\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mAS\u001b[39;49;00m\u001b[37m \u001b[39;49;00mv1(holder_name,\u001b[37m \u001b[39;49;00mshares,\u001b[37m \u001b[39;49;00mdate_reported,\u001b[37m \u001b[39;49;00mpercent_out,\u001b[37m \u001b[39;49;00mvalue)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:spark_ai:SQL query for the ingestion:\n",
            "\u001b[34mCREATE\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mOR\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mREPLACE\u001b[39;49;00m\u001b[37m \u001b[39;49;00mTEMP\u001b[37m \u001b[39;49;00m\u001b[34mVIEW\u001b[39;49;00m\u001b[37m \u001b[39;49;00mspark_ai_temp_view_630261\u001b[37m \u001b[39;49;00m\u001b[34mAS\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mSELECT\u001b[39;49;00m\u001b[37m \u001b[39;49;00m*\u001b[37m \u001b[39;49;00m\u001b[34mFROM\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mVALUES\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Vanguard Group Inc'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1299997133\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m8\u001b[39;49;00m.\u001b[34m36\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m251653447386\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Blackrock Inc.'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1031407553\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m6\u001b[39;49;00m.\u001b[34m63\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m199659875998\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Berkshire Hathaway, Inc'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m915560382\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m5\u001b[39;49;00m.\u001b[34m89\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m177234180424\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'State Street Corporation'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m569291690\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m3\u001b[39;49;00m.\u001b[34m66\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m110203486392\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'FMR, LLC'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m298321726\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m92\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m57749120265\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Geode Capital Management, LLC'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m296103070\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m90\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m57319632832\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Price (T.Rowe) Associates Inc'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m216307878\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m39\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m41872879419\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Morgan Stanley'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m206732960\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m33\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m40019366775\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Northern Trust Corporation'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m168874976\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Sep 29, 2023'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m09\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m32690818163\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "(\u001b[33m'Norges Bank Investment Management'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m167374278\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m'Dec 30, 2022'\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m1\u001b[39;49;00m.\u001b[34m08\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[34m32400313041\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mAS\u001b[39;49;00m\u001b[37m \u001b[39;49;00mv1(holder_name,\u001b[37m \u001b[39;49;00mshares,\u001b[37m \u001b[39;49;00mdate_reported,\u001b[37m \u001b[39;49;00mpercent_out,\u001b[37m \u001b[39;49;00mvalue)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO: \u001b[0mStoring data into temp view: spark_ai_temp_view_630261\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:spark_ai:Storing data into temp view: spark_ai_temp_view_630261\n",
            "\n"
          ]
        }
      ],
      "source": [
        "holders_dataframe = spark_ai.create_df(\"https://finance.yahoo.com/quote/AAPL/holders?p=AAPL\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvO1T7d625-g"
      },
      "source": [
        "4. Show records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBfCOnQW0_Tw",
        "outputId": "9f457d0f-07b1-4153-ef3d-a82e9de4406c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+----------+-------------+-----------+------------+\n",
            "|         holder_name|    shares|date_reported|percent_out|       value|\n",
            "+--------------------+----------+-------------+-----------+------------+\n",
            "|  Vanguard Group Inc|1299997133| Sep 29, 2023|       8.36|251653447386|\n",
            "|      Blackrock Inc.|1031407553| Sep 29, 2023|       6.63|199659875998|\n",
            "|Berkshire Hathawa...| 915560382| Sep 29, 2023|       5.89|177234180424|\n",
            "|State Street Corp...| 569291690| Sep 29, 2023|       3.66|110203486392|\n",
            "|            FMR, LLC| 298321726| Sep 29, 2023|       1.92| 57749120265|\n",
            "+--------------------+----------+-------------+-----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "holders_dataframe.show(n=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQVxn-3Z3F7o"
      },
      "source": [
        "5. Plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tYw_E6Eq0_WH",
        "outputId": "af7a72b7-8b11-42d0-f7a8-8e1c2c2e6594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO: \u001b[0mHere is a Python code snippet that meets all the requirements:\n",
            "\n",
            "\n",
            "```\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SparkSession\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mplotly\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexpress\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpx\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Start Spark session\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "spark = SparkSession.builder.getOrCreate()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Assuming df is the DataFrame\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Perform aggregation\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_agg = df.groupBy(\u001b[33m'\u001b[39;49;00m\u001b[33mholder_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).sum(\u001b[33m'\u001b[39;49;00m\u001b[33mshares\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Convert to pandas DataFrame\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_pd = df_agg.toPandas()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Plot using plotly\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "fig = px.bar(df_pd, x=\u001b[33m'\u001b[39;49;00m\u001b[33mholder_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, y=\u001b[33m'\u001b[39;49;00m\u001b[33msum(shares)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, title=\u001b[33m'\u001b[39;49;00m\u001b[33mShares by Holder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "fig.show()\u001b[37m\u001b[39;49;00m\n",
            "```\n",
            "\n",
            "This code first starts a Spark session. Then it performs an aggregation on the `df` DataFrame, summing the 'shares' for each 'holder_name'. The aggregated DataFrame is then converted to a pandas DataFrame. Finally, a bar plot is created using plotly, with 'holder_name' on the x-axis and the sum of 'shares' on the y-axis. The plot is displayed directly.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:spark_ai:Here is a Python code snippet that meets all the requirements:\n",
            "\n",
            "\n",
            "```\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SparkSession\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mplotly\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexpress\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpx\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Start Spark session\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "spark = SparkSession.builder.getOrCreate()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Assuming df is the DataFrame\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Perform aggregation\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_agg = df.groupBy(\u001b[33m'\u001b[39;49;00m\u001b[33mholder_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).sum(\u001b[33m'\u001b[39;49;00m\u001b[33mshares\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Convert to pandas DataFrame\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_pd = df_agg.toPandas()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Plot using plotly\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "fig = px.bar(df_pd, x=\u001b[33m'\u001b[39;49;00m\u001b[33mholder_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, y=\u001b[33m'\u001b[39;49;00m\u001b[33msum(shares)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, title=\u001b[33m'\u001b[39;49;00m\u001b[33mShares by Holder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "fig.show()\u001b[37m\u001b[39;49;00m\n",
            "```\n",
            "\n",
            "This code first starts a Spark session. Then it performs an aggregation on the `df` DataFrame, summing the 'shares' for each 'holder_name'. The aggregated DataFrame is then converted to a pandas DataFrame. Finally, a bar plot is created using plotly, with 'holder_name' on the x-axis and the sum of 'shares' on the y-axis. The plot is displayed directly.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"210091db-0200-47a1-8506-78eaec1aadd5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"210091db-0200-47a1-8506-78eaec1aadd5\")) {                    Plotly.newPlot(                        \"210091db-0200-47a1-8506-78eaec1aadd5\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"holder_name=%{x}\\u003cbr\\u003esum(shares)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"Vanguard Group Inc\",\"FMR, LLC\",\"Berkshire Hathaway, Inc\",\"State Street Corporation\",\"Blackrock Inc.\",\"Geode Capital Management, LLC\",\"Price (T.Rowe) Associates Inc\",\"Morgan Stanley\",\"Northern Trust Corporation\",\"Norges Bank Investment Management\"],\"xaxis\":\"x\",\"y\":[1299997133,298321726,915560382,569291690,1031407553,296103070,216307878,206732960,168874976,167374278],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"holder_name\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"sum(shares)\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Shares by Holder\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('210091db-0200-47a1-8506-78eaec1aadd5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"from pyspark.sql import SparkSession\\nimport pandas as pd\\nimport plotly.express as px\\n\\n# Start Spark session\\nspark = SparkSession.builder.getOrCreate()\\n\\n# Assuming df is the DataFrame\\n# Perform aggregation\\ndf_agg = df.groupBy('holder_name').sum('shares')\\n\\n# Convert to pandas DataFrame\\ndf_pd = df_agg.toPandas()\\n\\n# Plot using plotly\\nfig = px.bar(df_pd, x='holder_name', y='sum(shares)', title='Shares by Holder')\\nfig.show()\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "holders_dataframe.ai.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MxaR4NSx0_Yh",
        "outputId": "9a64aefd-0ced-4d4c-a44c-7fb27b33cca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO: \u001b[0mHere is a Python code snippet that uses PySpark and Plotly to create a pie chart of Apple's top holders and their share percentages:\n",
            "\n",
            "\n",
            "```\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SparkSession\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mplotly\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexpress\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpx\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Start Spark session\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "spark = SparkSession.builder.getOrCreate()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Assuming df is the DataFrame with the required columns\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Aggregate the data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_agg = df.groupBy(\u001b[33m'\u001b[39;49;00m\u001b[33mholder_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).agg({\u001b[33m'\u001b[39;49;00m\u001b[33mshares\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33msum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m})\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Convert the aggregated Spark DataFrame to a Pandas DataFrame\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_pandas = df_agg.toPandas()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Calculate the percentage of shares for each holder\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_pandas[\u001b[33m'\u001b[39;49;00m\u001b[33mpercent_shares\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = df_pandas[\u001b[33m'\u001b[39;49;00m\u001b[33msum(shares)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] / df_pandas[\u001b[33m'\u001b[39;49;00m\u001b[33msum(shares)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].sum() * \u001b[34m100\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Create a pie chart using Plotly\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "fig = px.pie(df_pandas, values=\u001b[33m'\u001b[39;49;00m\u001b[33mpercent_shares\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, names=\u001b[33m'\u001b[39;49;00m\u001b[33mholder_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, title=\u001b[33m'\u001b[39;49;00m\u001b[33mApple\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33ms Top Holders Share Percentages\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Display the plot\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "fig.show()\u001b[37m\u001b[39;49;00m\n",
            "```\n",
            "\n",
            "This code first aggregates the data by holder name and sums up the shares for each holder. It then converts the aggregated Spark DataFrame to a Pandas DataFrame. After that, it calculates the percentage of shares for each holder. Finally, it creates a pie chart using Plotly and displays the plot.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:spark_ai:Here is a Python code snippet that uses PySpark and Plotly to create a pie chart of Apple's top holders and their share percentages:\n",
            "\n",
            "\n",
            "```\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SparkSession\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mplotly\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexpress\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpx\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Start Spark session\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "spark = SparkSession.builder.getOrCreate()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Assuming df is the DataFrame with the required columns\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Aggregate the data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_agg = df.groupBy(\u001b[33m'\u001b[39;49;00m\u001b[33mholder_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).agg({\u001b[33m'\u001b[39;49;00m\u001b[33mshares\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33msum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m})\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Convert the aggregated Spark DataFrame to a Pandas DataFrame\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_pandas = df_agg.toPandas()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Calculate the percentage of shares for each holder\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "df_pandas[\u001b[33m'\u001b[39;49;00m\u001b[33mpercent_shares\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = df_pandas[\u001b[33m'\u001b[39;49;00m\u001b[33msum(shares)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] / df_pandas[\u001b[33m'\u001b[39;49;00m\u001b[33msum(shares)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].sum() * \u001b[34m100\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Create a pie chart using Plotly\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "fig = px.pie(df_pandas, values=\u001b[33m'\u001b[39;49;00m\u001b[33mpercent_shares\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, names=\u001b[33m'\u001b[39;49;00m\u001b[33mholder_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, title=\u001b[33m'\u001b[39;49;00m\u001b[33mApple\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33ms Top Holders Share Percentages\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Display the plot\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "fig.show()\u001b[37m\u001b[39;49;00m\n",
            "```\n",
            "\n",
            "This code first aggregates the data by holder name and sums up the shares for each holder. It then converts the aggregated Spark DataFrame to a Pandas DataFrame. After that, it calculates the percentage of shares for each holder. Finally, it creates a pie chart using Plotly and displays the plot.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5a613cee-cbe2-4e71-bea2-31e79c2f8237\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5a613cee-cbe2-4e71-bea2-31e79c2f8237\")) {                    Plotly.newPlot(                        \"5a613cee-cbe2-4e71-bea2-31e79c2f8237\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"holder_name=%{label}\\u003cbr\\u003epercent_shares=%{value}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"labels\":[\"Vanguard Group Inc\",\"FMR, LLC\",\"Berkshire Hathaway, Inc\",\"State Street Corporation\",\"Blackrock Inc.\",\"Geode Capital Management, LLC\",\"Price (T.Rowe) Associates Inc\",\"Morgan Stanley\",\"Northern Trust Corporation\",\"Norges Bank Investment Management\"],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"values\":[25.14515014808265,5.77027779699355,17.709195420991676,11.011505071608278,19.949965369694024,5.727363519084181,4.18392774295691,3.9987252185405895,3.2664584559309597,3.2374312561171825],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Apple's Top Holders Share Percentages\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5a613cee-cbe2-4e71-bea2-31e79c2f8237');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"from pyspark.sql import SparkSession\\nimport pandas as pd\\nimport plotly.express as px\\n\\n# Start Spark session\\nspark = SparkSession.builder.getOrCreate()\\n\\n# Assuming df is the DataFrame with the required columns\\n# Aggregate the data\\ndf_agg = df.groupBy('holder_name').agg({'shares': 'sum'})\\n\\n# Convert the aggregated Spark DataFrame to a Pandas DataFrame\\ndf_pandas = df_agg.toPandas()\\n\\n# Calculate the percentage of shares for each holder\\ndf_pandas['percent_shares'] = df_pandas['sum(shares)'] / df_pandas['sum(shares)'].sum() * 100\\n\\n# Create a pie chart using Plotly\\nfig = px.pie(df_pandas, values='percent_shares', names='holder_name', title='Apple\\\\'s Top Holders Share Percentages')\\n\\n# Display the plot\\nfig.show()\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "holders_dataframe.ai.plot(\"Pie chart for Apple's top holders, show their name and share percentages\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKW6jtnG1H-W",
        "outputId": "6dcb20d2-a780-45c7-d6f1-207bd1a12c2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO: \u001b[0mCreating temp view for the transform:\n",
            "df.createOrReplaceTempView(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark_ai_temp_view__239153240\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:spark_ai:Creating temp view for the transform:\n",
            "df.createOrReplaceTempView(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark_ai_temp_view__239153240\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I will query the holder_name and percent_out columns, ordering by percent_out in descending order.\n",
            "Action: query_validation\n",
            "Action Input: SELECT holder_name, percent_out FROM spark_ai_temp_view__239153240 ORDER BY percent_out DESC LIMIT 1\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mOK\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: SELECT holder_name, percent_out FROM spark_ai_temp_view__239153240 ORDER BY percent_out DESC LIMIT 1\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "+------------------+-----------+\n",
            "|       holder_name|percent_out|\n",
            "+------------------+-----------+\n",
            "|Vanguard Group Inc|       8.36|\n",
            "+------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_holder_dataframe = holders_dataframe.ai.transform(\"name with the highest percentage, and its percentage\")\n",
        "top_holder_dataframe.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfEBhH1n1IBQ",
        "outputId": "cd050a37-7a01-46f6-afaa-796cb9560257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO: \u001b[0mCreating temp view for the transform:\n",
            "df.createOrReplaceTempView(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark_ai_temp_view__239153240\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:spark_ai:Creating temp view for the transform:\n",
            "df.createOrReplaceTempView(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark_ai_temp_view__239153240\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I will query the holder_name and percent_out columns, ordering by percent_out in ascending order.\n",
            "Action: query_validation\n",
            "Action Input: SELECT holder_name, percent_out FROM spark_ai_temp_view__239153240 ORDER BY percent_out ASC LIMIT 1\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mOK\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: SELECT holder_name, percent_out FROM spark_ai_temp_view__239153240 ORDER BY percent_out ASC LIMIT 1\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "+--------------------+-----------+\n",
            "|         holder_name|percent_out|\n",
            "+--------------------+-----------+\n",
            "|Norges Bank Inves...|       1.08|\n",
            "+--------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_holder_dataframe = holders_dataframe.ai.transform(\"name with the lowest percentage, and its percentage\")\n",
        "top_holder_dataframe.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HrE9H1F1IDl",
        "outputId": "a6a457ba-e270-4ba8-9861-bc64c928a92c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO: \u001b[0mCreating temp view for the transform:\n",
            "df.createOrReplaceTempView(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark_ai_temp_view__239153240\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:spark_ai:Creating temp view for the transform:\n",
            "df.createOrReplaceTempView(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark_ai_temp_view__239153240\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I will query the holder_name and percent_out columns, ordering by percent_out in descending order and limiting the result to the top 3.\n",
            "Action: query_validation\n",
            "Action Input: SELECT holder_name, percent_out FROM spark_ai_temp_view__239153240 ORDER BY percent_out DESC LIMIT 3\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mOK\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: SELECT holder_name, percent_out FROM spark_ai_temp_view__239153240 ORDER BY percent_out DESC LIMIT 3\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "+--------------------+-----------+\n",
            "|         holder_name|percent_out|\n",
            "+--------------------+-----------+\n",
            "|  Vanguard Group Inc|       8.36|\n",
            "|      Blackrock Inc.|       6.63|\n",
            "|Berkshire Hathawa...|       5.89|\n",
            "+--------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_holder_dataframe = holders_dataframe.ai.transform(\"name with the top 3 highest percentage, and its percentage\")\n",
        "top_holder_dataframe.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXCYebGU1IF-",
        "outputId": "df29e11a-d0aa-400c-f55c-db369a085015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO: \u001b[0mCreating temp view for the transform:\n",
            "df.createOrReplaceTempView(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark_ai_temp_view__239153240\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:spark_ai:Creating temp view for the transform:\n",
            "df.createOrReplaceTempView(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark_ai_temp_view__239153240\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I will query the holder_name and percent_out columns, ordering by percent_out in ascending order and limit the result to 3.\n",
            "Action: query_validation\n",
            "Action Input: SELECT holder_name, percent_out FROM spark_ai_temp_view__239153240 ORDER BY percent_out ASC LIMIT 3\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mOK\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: SELECT holder_name, percent_out FROM spark_ai_temp_view__239153240 ORDER BY percent_out ASC LIMIT 3\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "+--------------------+-----------+\n",
            "|         holder_name|percent_out|\n",
            "+--------------------+-----------+\n",
            "|Norges Bank Inves...|       1.08|\n",
            "|Northern Trust Co...|       1.09|\n",
            "|      Morgan Stanley|       1.33|\n",
            "+--------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_holder_dataframe = holders_dataframe.ai.transform(\"name with the top 3 lowest percentage, and its percentage\")\n",
        "top_holder_dataframe.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "obUbLo611IIm",
        "outputId": "39e14198-eeb9-4fcd-cd51-c37781b2e0dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain_community.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-4 in organization org-eF2St7DWo6Vy2UXYqmzJ5dGu on tokens_usage_based per min: Limit 10000, Used 9036, Requested 1013. Please try again in 294ms. Visit https://platform.openai.com/account/rate-limits to learn more..\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"In summary, this dataframe is retrieving the top 3 records with the smallest 'percent_out' values from the temporary view 'spark_ai_temp_view__239153240'. The results are sorted in ascending order by 'percent_out'. The output includes the 'holder_name' and 'percent_out' fields.\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_holder_dataframe.ai.explain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C89HbsZE1Ihb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
